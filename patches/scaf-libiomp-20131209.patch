diff --git a/src/kmp.h b/src/kmp.h
index 4e7dec0..8e675fd 100644
--- a/src/kmp.h
+++ b/src/kmp.h
@@ -273,7 +273,8 @@ enum dynamic_mode {
 #endif /* USE_LOAD_BALANCE */
     dynamic_random,
     dynamic_thread_limit,
-    dynamic_max
+    dynamic_max,
+    dynamic_scaf
 };
 
 /* external schedule constants, duplicate enum omp_sched in omp.h in order to not include it here */
diff --git a/src/kmp_csupport.c b/src/kmp_csupport.c
index 0fcf09b..7a99985 100644
--- a/src/kmp_csupport.c
+++ b/src/kmp_csupport.c
@@ -40,6 +40,12 @@
 #include "kmp_itt.h"
 #include "kmp_error.h"
 
+extern "C"
+{
+#include <scaf.h>
+}
+extern int scaf_last_allocation;
+
 #define MAX_MESSAGE 512
 
 /* ------------------------------------------------------------------------ */
@@ -301,6 +307,56 @@ __kmpc_fork_call(ident_t *loc, kmp_int32 argc, kmpc_micro microtask, ...)
     va_list     ap;
     va_start(   ap, microtask );
 
+    //SCAF: set up an ad-hoc structure to convert our functor to accept a
+    //single void pointer argument
+    struct squishedargs {
+      int argc;
+      void **args;
+      microtask_t microtask;
+      int gtid;
+      ident_t *loc;
+    };
+
+    //SCAF: collect arguments for the section/task itself
+    void* args[argc];
+    {
+       va_list ap_l;
+       va_start(ap_l, microtask);
+       void** argv = args;
+       int i;
+       for( i=argc-1; i >= 0; --i )
+          *argv++ = va_arg( ap_l, void * );
+    }
+
+    //SCAF: store all arguments for the functor into a single blob
+    struct squishedargs funcdata;
+    funcdata.argc = argc;
+    funcdata.args = args;
+    funcdata.microtask = microtask;
+    funcdata.gtid = gtid;
+    funcdata.loc = loc;
+
+    //SCAF: now describe a functor for passing to libscaf, which will
+    //eventually run the serialized section as local::serialexecute(&funcdata).
+    //Note that the entire experimental process will always just stop after
+    //this runs, so we needn't make any attempt to clean up afterward.
+    struct local
+    {
+       static void serialexecute(void *data){
+          struct squishedargs *fd = (struct squishedargs*)data;
+          __kmpc_serialized_parallel(fd->loc, fd->gtid);
+          __kmp_invoke_microtask(fd->microtask, fd->gtid, 0, fd->argc, fd->args);
+       }
+    };
+
+    //SCAF: Just to be clear, collect our usual fn, data pair.
+    void (*fn) (void*) = local::serialexecute;
+    void *data = &funcdata;
+
+    //SCAF: Re-using the GOMP port's create function, launch the experiment.
+    scaf_last_allocation = scaf_section_start((void*)microtask);
+    scaf_gomp_training_create(fn, data);
+
     __kmp_fork_call( loc, gtid, TRUE,
             argc,
             VOLATILE_CAST(microtask_t) microtask,
@@ -314,6 +370,9 @@ __kmpc_fork_call(ident_t *loc, kmp_int32 argc, kmpc_micro microtask, ...)
             );
     __kmp_join_call( loc, gtid );
 
+    scaf_section_end();
+    scaf_gomp_training_destroy();
+
     va_end( ap );
   }
 }
diff --git a/src/kmp_runtime.c b/src/kmp_runtime.c
index 659fe76..4ae0160 100644
--- a/src/kmp_runtime.c
+++ b/src/kmp_runtime.c
@@ -45,6 +45,12 @@
 #include "kmp_io.h"
 #include "kmp_error.h"
 
+extern "C"
+{
+#include <scaf.h>
+}
+int scaf_last_allocation = 0;
+
 /* these are temporary issues to be dealt with */
 #define KMP_USE_PRCTL 0
 #define KMP_USE_POOLED_ALLOC 0
@@ -2152,7 +2158,7 @@ __kmp_end_split_barrier( enum barrier_type bt, int gtid )
  */
 static int
 __kmp_reserve_threads( kmp_root_t *root, kmp_team_t *parent_team,
-   int master_tid, int set_nthreads
+   int master_tid, int set_nthreads, microtask_t microtask
 #if OMP_40_ENABLED
   , int enter_teams
 #endif /* OMP_40_ENABLED */
@@ -2236,6 +2242,24 @@ __kmp_reserve_threads( kmp_root_t *root, kmp_team_t *parent_team,
             }
         }
     }
+    else if ( __kmp_global.g.g_dynamic_mode == dynamic_scaf ) {
+        new_nthreads = scaf_last_allocation - __kmp_nth + (root->r.r_active ? 1
+          : root->r.r_hot_team->t.t_nproc);
+        //new_nthreads = scaf_last_allocation;
+        if ( new_nthreads <= 1 ) {
+            KC_TRACE( 10, ( "__kmp_reserve_threads: T#%d thread limit reduced reservation to 1 thread\n",
+              master_tid ));
+            return 1;
+        }
+        if ( new_nthreads < set_nthreads ) {
+            KC_TRACE( 10, ( "__kmp_reserve_threads: T#%d thread limit reduced reservation to %d threads\n",
+              master_tid, new_nthreads ));
+        }
+        else if ( new_nthreads > set_nthreads ) {
+            KC_TRACE( 10, ( "__kmp_reserve_threads: T#%d thread limit increased reservation to %d threads\n",
+              master_tid, new_nthreads ));
+        }
+    }
     else {
         KMP_ASSERT( 0 );
     }
@@ -2567,7 +2591,7 @@ __kmp_fork_call(
     {
         nthreads = master_set_numthreads ?
             master_set_numthreads : get__nproc_2( parent_team, master_tid );
-        nthreads = __kmp_reserve_threads( root, parent_team, master_tid, nthreads
+        nthreads = __kmp_reserve_threads( root, parent_team, master_tid, nthreads, microtask
 #if OMP_40_ENABLED
         // AC: If we execute teams from parallel region (on host), then teams
         //     should be created but each can only have 1 thread if nesting is disabled.
diff --git a/src/kmp_settings.c b/src/kmp_settings.c
index 40c0499..00788d4 100644
--- a/src/kmp_settings.c
+++ b/src/kmp_settings.c
@@ -3357,6 +3357,9 @@ __kmp_stg_parse_kmp_dynamic_mode( char const * name, char const * value, void *
     else if ( __kmp_str_match( "random", 1, value ) ) {
         __kmp_global.g.g_dynamic_mode = dynamic_random;
     }
+    else if ( __kmp_str_match( "scaf", 0, value ) ) {
+        __kmp_global.g.g_dynamic_mode = dynamic_scaf;
+    }
     else {
         KMP_WARNING( StgInvalidValue, name, value );
     }
